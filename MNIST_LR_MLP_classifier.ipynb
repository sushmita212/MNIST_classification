{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supported-feedback",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "diverse-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-skiing",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-failure",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "talented-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_train = datasets.MNIST(root=\"./datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handled-factory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MNIST training examples: 60000\n",
      "Number of MNIST test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of MNIST training examples: {len(mnist_train)}\")\n",
    "print(f\"Number of MNIST test examples: {len(mnist_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-cleanup",
   "metadata": {},
   "source": [
    "### Example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "british-option",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default image shape: torch.Size([1, 28, 28])\n",
      "Reshaped image shape: torch.Size([28, 28])\n",
      "The label for this image: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pick out an image and it's label from the training set\n",
    "image, label = mnist_train[2]\n",
    "\n",
    "# Plotting the image. Here the 1 in the 0th dimension means the image has only 1 color component\n",
    "print(\"Default image shape: {}\".format(image.shape))\n",
    "# Get rid of the zeroth dimension to visualize the image with imshow\n",
    "image = image.reshape([28,28])\n",
    "print(\"Reshaped image shape: {}\".format(image.shape))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "# Print the label\n",
    "print(\"The label for this image: {}\".format(label));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-socket",
   "metadata": {},
   "source": [
    "It is convenient to use a DataLoader that takes care of batching and shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "increased-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-badge",
   "metadata": {},
   "source": [
    "Example of a minibatch drawn from DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indirect-scope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the minibatch of images: torch.Size([100, 1, 28, 28])\n",
      "Shape of the minibatch of labels: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "data_train_iter = iter(train_loader)\n",
    "images, labels = next(data_train_iter)\n",
    "\n",
    "print(\"Shape of the minibatch of images: {}\".format(images.shape))\n",
    "print(\"Shape of the minibatch of labels: {}\".format(labels.shape))\n",
    "# print(data_train_iter.next())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-trustee",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "outside-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input x: torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "x = images.view(-1, 28*28)#flatten and divide into 28*28 elements\n",
    "print(\"The shape of input x: {}\".format(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "monthly-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inittialize parameters\n",
    "W = torch.randn(784,10)/np.sqrt(784)\n",
    "W.requires_grad_()\n",
    "b = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "streaming-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.SGD([W,b], lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "union-assets",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c55c07d72854efa8b0d705ac7774500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training\n",
    "for images, labels in tqdm(train_loader):\n",
    "    # zero out the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    x = images.view(-1, 28*28)\n",
    "    y = torch.matmul(x,W) + b\n",
    "    cross_entropy = F.cross_entropy(y, labels)\n",
    "    \n",
    "    # Backward pass\n",
    "    cross_entropy.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "automated-burden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5382752e24cf46bbab41e1d028550625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9028000235557556\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate through test set minibatchs \n",
    "    for images, labels in tqdm(test_loader):\n",
    "        # Forward pass\n",
    "        x = images.view(-1, 28*28)\n",
    "        y = torch.matmul(x, W) + b\n",
    "        \n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions == labels).float())\n",
    "    \n",
    "print('Test accuracy: {}'.format(correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-lucas",
   "metadata": {},
   "source": [
    "### LR using nn.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "under-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "swiss-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building and training\n",
    "# define LR model\n",
    "class MNIST_Logistic_Regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "# load data\n",
    "mnist_train = datasets.MNIST(root=\"./datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)\n",
    "\n",
    "# Training\n",
    "# Instantiate model\n",
    "model = MNIST_Logistic_Regression()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr =0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "portuguese-language",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778fca3262a44f178f46addc0a9cc143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iterate through training data minibatches\n",
    "for images, labels in tqdm(train_loader):\n",
    "    # zero out the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    x = images.view(-1, 28*28)\n",
    "    y = model(x)\n",
    "    loss = criterion(y, labels)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "august-intellectual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beae0f87231a4190b8df4cc0ec660ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.902400016784668\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "correcrt = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "# Iterate through test set minibatches\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        x = images.view(-1, 28*28)\n",
    "        y = model(x)\n",
    "        \n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correcrt += torch.sum(predictions == labels)\n",
    "print(f\"Test accuracy:{correcrt.float()/total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-sterling",
   "metadata": {},
   "source": [
    "## Multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-inspector",
   "metadata": {},
   "source": [
    "Next, we will use a 2-layer MLP for MNIST digit classification. The components of our model are as follows:\n",
    "<br>\n",
    "- Images (784 dimensions)\n",
    "<br>\n",
    "- First (input) layer (784x500 dimensions) -> Nonlinearity (ReLU)\n",
    "<br>\n",
    "- Second layer (500x10 dimensions) \n",
    "<br>\n",
    "- Fully connected 10 hidden units -> softmax (Note: torch.nn.CrossEntropyLoss() combines softmax and cross-entropy. So we don't need to implement it explicitly.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "apart-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "younger-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building and training\n",
    "# define LR model\n",
    "class MNIST_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # first layer with ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # second layer\n",
    "        return self.fc2(x)\n",
    "\n",
    "# load data\n",
    "mnist_train = datasets.MNIST(root=\"./datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)\n",
    "\n",
    "# Training\n",
    "# Instantiate model\n",
    "model = MNIST_MLP()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr =0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "computational-collar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d81d37084c4adeadf95b8e41196c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iterate through training data minibatches\n",
    "for images, labels in tqdm(train_loader):\n",
    "    # zero out the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    x = images.view(-1, 28*28)\n",
    "    y = model(x)\n",
    "    loss = criterion(y, labels)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "returning-blink",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff7652a05f740638b81e9988753ce29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.9200999736785889\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "correcrt = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "# Iterate through test set minibatches\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        x = images.view(-1, 28*28)\n",
    "        y = model(x)\n",
    "        \n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correcrt += torch.sum(predictions == labels)\n",
    "print(f\"Test accuracy:{correcrt.float()/total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-documentation",
   "metadata": {},
   "source": [
    "We see an improvement in test accuracy from 0.90 for LR model to 0.92 for the MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-chick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3.12_torch",
   "language": "python",
   "name": "python_3.12_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
